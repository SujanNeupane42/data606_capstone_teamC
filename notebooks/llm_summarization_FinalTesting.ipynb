{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c336bf52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/miniconda3/envs/capstone/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fb123b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-24 17:07:31 [__init__.py:244] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 17:07:34,200\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "from vllm import LLM, SamplingParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebad8dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HF_TOKEN\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4695dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun 24 17:08:05 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.133.20             Driver Version: 570.133.20     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A10G                    On  |   00000000:00:1E.0 Off |                    0 |\n",
      "|  0%   33C    P8              9W /  300W |       0MiB /  23028MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f39a366",
   "metadata": {},
   "source": [
    "# Loading our LLM onto vLLM and preparing tokenizer\n",
    "\n",
    "Selected LLM: [meta-llama/Llama-3.2-3B-Instruct](https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "709e2d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available!\n",
      "Using device: NVIDIA A10G\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available!\")\n",
    "    print(f\"Using device: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"No GPU. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8610daed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/Llama-3.2-3B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8681bfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_params = SamplingParams(temperature=0.1, top_p=1, max_tokens=512)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3586723d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-24 17:08:47 [config.py:823] This model supports multiple tasks: {'embed', 'generate', 'reward', 'classify', 'score'}. Defaulting to 'generate'.\n",
      "INFO 06-24 17:08:47 [config.py:2195] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "WARNING 06-24 17:08:49 [utils.py:2597] We must use the `spawn` multiprocessing start method. Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. See https://docs.vllm.ai/en/latest/usage/troubleshooting.html#python-multiprocessing for more information. Reason: CUDA is initialized\n",
      "WARNING 06-24 17:08:50 [env_override.py:17] NCCL_CUMEM_ENABLE is set to 0, skipping override. This may increase memory overhead with cudagraph+allreduce: https://github.com/NVIDIA/nccl/issues/1234\n",
      "INFO 06-24 17:08:53 [__init__.py:244] Automatically detected platform cuda.\n",
      "INFO 06-24 17:08:56 [core.py:455] Waiting for init message from front-end.\n",
      "INFO 06-24 17:08:56 [core.py:70] Initializing a V1 LLM engine (v0.9.1) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=25000, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[\"none\"],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\"],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"max_capture_size\":512,\"local_cache_dir\":null}\n",
      "WARNING 06-24 17:08:56 [utils.py:2737] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f4aeb5fa810>\n",
      "INFO 06-24 17:08:57 [parallel_state.py:1065] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "WARNING 06-24 17:08:57 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "INFO 06-24 17:08:57 [gpu_model_runner.py:1595] Starting to load model meta-llama/Llama-3.2-3B-Instruct...\n",
      "INFO 06-24 17:08:57 [gpu_model_runner.py:1600] Loading model from scratch...\n",
      "INFO 06-24 17:08:57 [cuda.py:252] Using Flash Attention backend on V1 engine.\n",
      "INFO 06-24 17:08:58 [weight_utils.py:292] Using model weights format ['*.safetensors']\n",
      "INFO 06-24 17:09:26 [weight_utils.py:308] Time spent downloading weights for meta-llama/Llama-3.2-3B-Instruct: 28.542845 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  4.90it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  1.91it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.10it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-24 17:09:28 [default_loader.py:272] Loading weights took 1.19 seconds\n",
      "INFO 06-24 17:09:28 [gpu_model_runner.py:1624] Model loading took 6.0165 GiB and 30.227260 seconds\n",
      "INFO 06-24 17:09:34 [backends.py:462] Using cache directory: /home/ec2-user/.cache/vllm/torch_compile_cache/63818febe3/rank_0_0 for vLLM's torch.compile\n",
      "INFO 06-24 17:09:34 [backends.py:472] Dynamo bytecode transform time: 5.78 s\n",
      "INFO 06-24 17:09:38 [backends.py:161] Cache the graph of shape None for later use\n",
      "INFO 06-24 17:10:00 [backends.py:173] Compiling a graph for general shape takes 25.63 s\n",
      "INFO 06-24 17:10:08 [monitor.py:34] torch.compile takes 31.41 s in total\n",
      "INFO 06-24 17:10:09 [gpu_worker.py:227] Available KV cache memory: 12.61 GiB\n",
      "INFO 06-24 17:10:10 [kv_cache_utils.py:715] GPU KV cache size: 118,080 tokens\n",
      "INFO 06-24 17:10:10 [kv_cache_utils.py:719] Maximum concurrency for 25,000 tokens per request: 4.72x\n",
      "INFO 06-24 17:10:32 [gpu_model_runner.py:2048] Graph capturing finished in 22 secs, took 0.45 GiB\n",
      "INFO 06-24 17:10:32 [core.py:171] init engine (profile, create kv cache, warmup model) took 64.07 seconds\n"
     ]
    }
   ],
   "source": [
    "llm = LLM(model=model_id, dtype=torch.bfloat16, max_model_len=25000) # one of the prompts has lots of tokens so"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd889f8f",
   "metadata": {},
   "source": [
    "# Testing on a single prompt for speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3a25e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = '''You are an expert summarizer helping a user prepare input for a sentence embedding model with a strict 512-token input limit.\n",
    "The user will always include the full **title** of the news article. Your job is to **rewrite or summarize the news article text only**, using no more than the available tokens provided. The goal is to preserve **all important meaning** from the article without exceeding the token budget.\n",
    "\n",
    "You must:\n",
    "- Leave the title unchanged\n",
    "- Output **only the rewritten article text**\n",
    "- Not include anything non-relevant stuff in your response\n",
    "\n",
    "You will be provided Input details.\n",
    "'''\n",
    "\n",
    "prompt = '''Input details:\n",
    "\n",
    "    Title: LAW ENFORCEMENT ON HIGH ALERT Following Threats Against Cops And Whites On 9-11By #BlackLivesMatter And #FYF911 Terrorists [VIDEO]\n",
    "\n",
    "    Title Token Count: 35\n",
    "\n",
    "    Original Text: No comment is expected from Barack Obama Members of the #FYF911 or #FukYoFlag and #BlackLivesMatter movements called for the lynching and hanging of white people and cops. They encouraged others on a radio show Tuesday night to  turn the tide  and kill white people and cops to send a message about the killing of black people in America.One of the F***YoFlag organizers is called  Sunshine.  She has a radio blog show hosted from Texas called,  Sunshine s F***ing Opinion Radio Show. A snapshot of her #FYF911 @LOLatWhiteFear Twitter page at 9:53 p.m. shows that she was urging supporters to  Call now!! #fyf911 tonight we continue to dismantle the illusion of white Below is a SNAPSHOT Twitter Radio Call Invite   #FYF911The radio show aired at 10:00 p.m. eastern standard time.During the show, callers clearly call for  lynching  and  killing  of white people.A 2:39 minute clip from the radio show can be heard here. It was provided to Breitbart Texas by someone who would like to be referred to as  Hannibal.  He has already received death threats as a result of interrupting #FYF911 conference calls.An unidentified black man said  when those mother f**kers are by themselves, that s when when we should start f***ing them up. Like they do us, when a bunch of them ni**ers takin  one of us out, that s how we should roll up.  He said,  Cause we already roll up in gangs anyway. There should be six or seven black mother f**ckers, see that white person, and then lynch their ass. Let s turn the tables. They conspired that if  cops started losing people,  then  there will be a state of emergency. He speculated that one of two things would happen,  a big-ass [R s?????] war,  or  ni**ers, they are going to start backin  up. We are already getting killed out here so what the f**k we got to lose? Sunshine could be heard saying,  Yep, that s true. That s so f**king true. He said,  We need to turn the tables on them. Our kids are getting shot out here. Somebody needs to become a sacrifice on their side.He said,  Everybody ain t down for that s**t, or whatever, but like I say, everybody has a different position of war.  He continued,  Because they don t give a f**k anyway.  He said again,  We might as well utilized them for that s**t and turn the tables on these n**ers. He said, that way  we can start lookin  like we ain t havin  that many casualties, and there can be more causalities on their side instead of ours. They are out their killing black people, black lives don t matter, that s what those mother f**kers   so we got to make it matter to them. Find a mother f**ker that is alone. Snap his ass, and then f***in hang him from a damn tree. Take a picture of it and then send it to the mother f**kers. We  just need one example,  and  then people will start watchin .  This will turn the tables on s**t, he said. He said this will start  a trickle-down effect.  He said that when one white person is hung and then they are just  flat-hanging,  that will start the  trickle-down effect.  He continued,  Black people are good at starting trends. He said that was how  to get the upper-hand. Another black man spoke up saying they needed to kill  cops that are killing us. The first black male said,  That will be the best method right there. Breitbart Texas previously reported how Sunshine was upset when  racist white people  infiltrated and disrupted one of her conference calls. She subsequently released the phone number of one of the infiltrators. The veteran immediately started receiving threatening calls.One of the #F***YoFlag movement supporters allegedly told a veteran who infiltrated their publicly posted conference call,  We are going to rape and gut your pregnant wife, and your f***ing piece of sh*t unborn creature will be hung from a tree. Breitbart Texas previously encountered Sunshine at a Sandra Bland protest at the Waller County Jail in Texas, where she said all white people should be killed. She told journalists and photographers,  You see this nappy-ass hair on my head?   That means I am one of those more militant Negroes.  She said she was at the protest because  these redneck mother-f**kers murdered Sandra Bland because she had nappy hair like me. #FYF911 black radicals say they will be holding the  imperial powers  that are actually responsible for the terrorist attacks on September 11th accountable on that day, as reported by Breitbart Texas. There are several websites and Twitter handles for the movement. Palmetto Star  describes himself as one of the head organizers. He said in a YouTube video that supporters will be burning their symbols of  the illusion of their superiority,  their  false white supremacy,  like the American flag, the British flag, police uniforms, and Ku Klux Klan hoods.Sierra McGrone or  Nocturnus Libertus  posted,  you too can help a young Afrikan clean their a** with the rag of oppression.  She posted two photos, one that appears to be herself, and a photo of a black man, wiping their naked butts with the American flag.For entire story: Breitbart News\n",
    "\n",
    "    Original Text Token Count: 1200\n",
    "\n",
    "    Max Allowed Total Tokens (Title + Text): 512\n",
    "\n",
    "    Available Tokens for Text Summary: 477\n",
    "\n",
    "\n",
    "    Now rewrite the article text only (not the title) within the available token budget. Your output should be clean, self-contained, and informative.\n",
    "    Do not add any information that is not present in the original news text. Your output must be exactly text summary and nothing else'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7d23b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79a2f044",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3094219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 100/100 [00:00<00:00, 371.81it/s]\n",
      "Processed prompts: 100%|██████████| 100/100 [00:10<00:00,  9.40it/s, est. speed input: 13907.32 toks/s, output: 2008.85 toks/s]\n"
     ]
    }
   ],
   "source": [
    "outputs = llm.generate([prompt]*100, sampling_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "174b6fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Members of the #FYF911 and #BlackLivesMatter movements called for the lynching and hanging of white people and cops in response to the killing of black people in America. A radio show host, Sunshine, urged supporters to kill white people and cops, saying \"we should start f***ing them up\" when they are alone. She suggested that if cops started losing people, there would be a state of emergency, leading to a big war or more black people rising up. Sunshine said, \"We need to turn the tables on them. Our kids are getting shot out here. Somebody needs to become a sacrifice on their side.\" Another black man said, \"Find a mother f**ker that is alone. Snap his ass, and then f***in hang him from a damn tree.\" He also suggested killing cops that are killing black people.\n"
     ]
    }
   ],
   "source": [
    "print(outputs[-1].outputs[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "232fe2db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.encode(outputs[-1].outputs[0].text, return_tensors='pt')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71676105",
   "metadata": {},
   "source": [
    "Well, processing 100 prompts took ~11 seconds, and we have an average of 2500 output tokens per second which is not bad at all. Lets process all prompts now. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5803d8d2",
   "metadata": {},
   "source": [
    "# Reading file and preparing prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5fc8be57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Summary_prompts_FinalTesting.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22d26ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19248, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Input details:\\n\\n    Title:  Donald Trump Sen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Input details:\\n\\n    Title:  Sheriff David Cl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Input details:\\n\\n    Title:  Trump Is So Obse...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Input details:\\n\\n    Title:  Former CIA Direc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Input details:\\n\\n    Title:  Heiress To Disne...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Input details:\\n\\n    Title:  Donald Trump Sen...      1\n",
       "1  Input details:\\n\\n    Title:  Sheriff David Cl...      1\n",
       "2  Input details:\\n\\n    Title:  Trump Is So Obse...      1\n",
       "3  Input details:\\n\\n    Title:  Former CIA Direc...      1\n",
       "4  Input details:\\n\\n    Title:  Heiress To Disne...      1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "385a3499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input details:\n",
      "\n",
      "    Title:  Donald Trump Sends Out Embarrassing New Year’s Eve Message; This is Disturbing\n",
      "\n",
      "    Title Token Count: 17\n",
      "\n",
      "    Original Text: Donald Trump just couldn t wish all Americans a Happy New Year and leave it at that. Instead, he had to give a shout out to his enemies, haters and  the very dishonest fake news media.  The former reality show star had just one job to do and he couldn t do it. As our Country rapidly grows stronger and smarter, I want to wish all of my friends, supporters, enemies, haters, and even the very dishonest Fake News Media, a Happy and Healthy New Year,  President Angry Pants tweeted.  2018 will be a great year for America! As our Country rapidly grows stronger and smarter, I want to wish all of my friends, supporters, enemies, haters, and even the very dishonest Fake News Media, a Happy and Healthy New Year. 2018 will be a great year for America!  Donald J. Trump (@realDonaldTrump) December 31, 2017Trump s tweet went down about as welll as you d expect.What kind of president sends a New Year s greeting like this despicable, petty, infantile gibberish? Only Trump! His lack of decency won t even allow him to rise above the gutter long enough to wish the American citizens a happy new year!  Bishop Talbert Swan (@TalbertSwan) December 31, 2017no one likes you  Calvin (@calvinstowell) December 31, 2017Your impeachment would make 2018 a great year for America, but I ll also accept regaining control of Congress.  Miranda Yaver (@mirandayaver) December 31, 2017Do you hear yourself talk? When you have to include that many people that hate you you have to wonder? Why do the they all hate me?  Alan Sandoval (@AlanSandoval13) December 31, 2017Who uses the word Haters in a New Years wish??  Marlene (@marlene399) December 31, 2017You can t just say happy new year?  Koren pollitt (@Korencarpenter) December 31, 2017Here s Trump s New Year s Eve tweet from 2016.Happy New Year to all, including to my many enemies and those who have fought me and lost so badly they just don t know what to do. Love!  Donald J. Trump (@realDonaldTrump) December 31, 2016This is nothing new for Trump. He s been doing this for years.Trump has directed messages to his  enemies  and  haters  for New Year s, Easter, Thanksgiving, and the anniversary of 9/11. pic.twitter.com/4FPAe2KypA  Daniel Dale (@ddale8) December 31, 2017Trump s holiday tweets are clearly not presidential.How long did he work at Hallmark before becoming President?  Steven Goodine (@SGoodine) December 31, 2017He s always been like this . . . the only difference is that in the last few years, his filter has been breaking down.  Roy Schulze (@thbthttt) December 31, 2017Who, apart from a teenager uses the term haters?  Wendy (@WendyWhistles) December 31, 2017he s a fucking 5 year old  Who Knows (@rainyday80) December 31, 2017So, to all the people who voted for this a hole thinking he would change once he got into power, you were wrong! 70-year-old men don t change and now he s a year older.Photo by Andrew Burton/Getty Images.\n",
      "\n",
      "    Original Text Token Count: 730\n",
      "\n",
      "    Max Allowed Total Tokens (Title + Text): 512\n",
      "\n",
      "    Available Tokens for Text Summary: 495\n",
      "\n",
      "\n",
      "    Now rewrite the article text only (not the title) within the available token budget. Your output should be clean, self-contained, and informative. \n",
      "    Do not add any information that is not present in the original news text or do not censor the text.\n",
      "    Your output must be exactly text summary and nothing else. You are also not allowed to water-down or censor the text as the text may contain sensitive information related \n",
      "    to politics, race or religion. Your job is to just summarize the text and not censor/water-down the text in any way shape or form.\n",
      "    The summary should be concise, informative, and maintain the original meaning.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(df.text.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20eb91c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3254ef9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>token_count</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Input details:\\n\\n    Title:  Donald Trump Sen...</td>\n",
       "      <td>1</td>\n",
       "      <td>1109</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Input details:\\n\\n    Title:  Sheriff David Cl...</td>\n",
       "      <td>1</td>\n",
       "      <td>1299</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Input details:\\n\\n    Title:  Trump Is So Obse...</td>\n",
       "      <td>1</td>\n",
       "      <td>1050</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Input details:\\n\\n    Title:  Former CIA Direc...</td>\n",
       "      <td>1</td>\n",
       "      <td>924</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Input details:\\n\\n    Title:  Heiress To Disne...</td>\n",
       "      <td>1</td>\n",
       "      <td>989</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19243</th>\n",
       "      <td>Input details:\\n\\n    Title: U.S., North Korea...</td>\n",
       "      <td>0</td>\n",
       "      <td>1237</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19244</th>\n",
       "      <td>Input details:\\n\\n    Title: U.S., North Korea...</td>\n",
       "      <td>0</td>\n",
       "      <td>1237</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19245</th>\n",
       "      <td>Input details:\\n\\n    Title: U.S., North Korea...</td>\n",
       "      <td>0</td>\n",
       "      <td>1160</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19246</th>\n",
       "      <td>Input details:\\n\\n    Title: North Korea shipm...</td>\n",
       "      <td>0</td>\n",
       "      <td>906</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19247</th>\n",
       "      <td>Input details:\\n\\n    Title: 'Fully committed'...</td>\n",
       "      <td>0</td>\n",
       "      <td>924</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19248 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label  token_count  \\\n",
       "0      Input details:\\n\\n    Title:  Donald Trump Sen...      1         1109   \n",
       "1      Input details:\\n\\n    Title:  Sheriff David Cl...      1         1299   \n",
       "2      Input details:\\n\\n    Title:  Trump Is So Obse...      1         1050   \n",
       "3      Input details:\\n\\n    Title:  Former CIA Direc...      1          924   \n",
       "4      Input details:\\n\\n    Title:  Heiress To Disne...      1          989   \n",
       "...                                                  ...    ...          ...   \n",
       "19243  Input details:\\n\\n    Title: U.S., North Korea...      0         1237   \n",
       "19244  Input details:\\n\\n    Title: U.S., North Korea...      0         1237   \n",
       "19245  Input details:\\n\\n    Title: U.S., North Korea...      0         1160   \n",
       "19246  Input details:\\n\\n    Title: North Korea shipm...      0          906   \n",
       "19247  Input details:\\n\\n    Title: 'Fully committed'...      0          924   \n",
       "\n",
       "                                                  prompt  \n",
       "0      <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "1      <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "2      <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "3      <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "4      <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "...                                                  ...  \n",
       "19243  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "19244  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "19245  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "19246  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "19247  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "\n",
       "[19248 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a0bc45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19248/19248 [00:51<00:00, 374.20it/s]\n"
     ]
    }
   ],
   "source": [
    "total_prompts = []\n",
    "token_count = []\n",
    "\n",
    "for current_prompt in tqdm(df.text.values):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": current_prompt},\n",
    "    ]\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    total_prompts.append(prompt)\n",
    "    encoded = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    token_count.append(len(encoded[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a338a01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['token_count'] = token_count\n",
    "df['prompt'] = total_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c22556b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(count    19248.000000\n",
       " mean      1176.497039\n",
       " std        509.352368\n",
       " min        775.000000\n",
       " 25%        922.000000\n",
       " 50%       1048.000000\n",
       " 75%       1266.000000\n",
       " max      10636.000000\n",
       " Name: token_count, dtype: float64,\n",
       " np.float64(7222.0))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"token_count\"].describe(), df[\"token_count\"].quantile(0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d0a9d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"token_count\"] < 20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7b5360e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19248, 4)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d905f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_prompts = df.prompt.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06873499",
   "metadata": {},
   "source": [
    "# Summarization using vLLM + Llama-3.2-3B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "475e5cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 24 Jun 2025\n",
      "\n",
      "You are an expert summarizer helping a user prepare input for a sentence embedding model with a strict 512-token input limit.\n",
      "The user will always include the full **title** of the news article. Your job is to **rewrite or summarize the news article text only**, using no more than the available tokens provided. The goal is to preserve **all important meaning** from the article without exceeding the token budget.\n",
      "\n",
      "You must:\n",
      "- Leave the title unchanged\n",
      "- Output **only the rewritten article text**\n",
      "- Not include anything non-relevant stuff in your response\n",
      "\n",
      "You will be provided Input details.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Input details:\n",
      "\n",
      "    Title: The People's Princess, Britons work to keep memory alive\n",
      "\n",
      "    Title Token Count: 15\n",
      "\n",
      "    Original Text: LONDON (Reuters) - Abdul Daoud spilt most of the cappuccino into the saucer the first time he served Princess Diana, his nerves getting the better of him. Almost 20 years on since she was killed when her car crashed in a Paris tunnel, he still works surrounded by pictures of the woman he calls  the princess of the people  in his cafe, named Diana, his very personal attempt to keep her memory alive.  My promise to her is to put this place as a tribute for her,  he said of his cafe, set up in 1989, near London s Kensington Gardens, home to the palace where Diana used to live.  For him, celebrating her life is  business as usual  at the cafe where visitors can eat Diana salads or Diana burgers and where he said she used to stop by regularly.   She is the princess of the people, always,  he said, adding that he does not believe she will ever be forgotten. But many younger Britons said that while they can understand the fascination with the princess, whose struggles to fit in to the royal household played out in the full glare of the media, they don t feel it themselves.       I think she maybe meant more to my mother,  said Stephen Butler in the west London area Diana used to live.  When she died I remember my mother shaking me awake and being quite devastated about it.  Student Shermine Grigorius was three-years-old when Diana died but after being told stories about the Princess of Wales by her mother, sees her as a  symbol of kindness .  While the royals have always been dutifully charitable, Diana was known for going beyond her in-laws, or even any celebrity at the time, in her philanthropy.  Whether in charity work or in royal life, she earned a reputation for being a rebel who defied convention: from campaigning for a worldwide ban on landmines despite opposition from the British government to flouting royal protocol to speak candidly about her experiences with bulimia and infidelity.   She bought a different side to the whole monarchy,  said Anika Wijuria, a 30-year-old project manager.  They were quite stiff and she was quite liberal.  At the Da Mario restaurant, Marco Molino remembers another side of Diana, describing a  down to earth  woman who liked to eat Italian dishes with her sons, Princes William and Harry, or friends.  Her personality was very normal, very down to earth, very friendly,  he said near an oil painting of Diana on the wall.  I think that s what she really wanted - a bit of normality ... Here was one of the places where she could achieve that.  Ronald van Bronkhorst, who has lived above Da Mario since the 70s, also said she never made flashy entrances.  Her legacy will never leave ... You think about her all the time, especially in the area we live in.  \n",
      "\n",
      "    Original Text Token Count: 587\n",
      "\n",
      "    Max Allowed Total Tokens (Title + Text): 512\n",
      "\n",
      "    Available Tokens for Text Summary: 497\n",
      "\n",
      "\n",
      "    Now rewrite the article text only (not the title) within the available token budget. Your output should be clean, self-contained, and informative. \n",
      "    Do not add any information that is not present in the original news text or do not censor the text.\n",
      "    Your output must be exactly text summary and nothing else. You are also not allowed to water-down or censor the text as the text may contain sensitive information related \n",
      "    to politics, race or religion. Your job is to just summarize the text and not censor/water-down the text in any way shape or form.\n",
      "    The summary should be concise, informative, and maintain the original meaning.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(total_prompts[-10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c9a7d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 24 Jun 2025\n",
      "\n",
      "You are an expert summarizer helping a user prepare input for a sentence embedding model with a strict 512-token input limit.\n",
      "The user will always include the full **title** of the news article. Your job is to **rewrite or summarize the news article text only**, using no more than the available tokens provided. The goal is to preserve **all important meaning** from the article without exceeding the token budget.\n",
      "\n",
      "You must:\n",
      "- Leave the title unchanged\n",
      "- Output **only the rewritten article text**\n",
      "- Not include anything non-relevant stuff in your response\n",
      "\n",
      "You will be provided Input details.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Input details:\n",
      "\n",
      "    Title: 'Fully committed' NATO backs new U.S. approach on Afghanistan\n",
      "\n",
      "    Title Token Count: 16\n",
      "\n",
      "    Original Text: BRUSSELS (Reuters) - NATO allies on Tuesday welcomed President Donald Trump s decision to commit more forces to Afghanistan, as part of a new U.S. strategy he said would require more troops and funding from America s partners. Having run for the White House last year on a pledge to withdraw swiftly from Afghanistan, Trump reversed course on Monday and promised a stepped-up military campaign against  Taliban insurgents, saying:  Our troops will fight to win .  U.S. officials said he had signed off on plans to send about 4,000 more U.S. troops to add to the roughly 8,400 now deployed in Afghanistan. But his speech did not define benchmarks for successfully ending the war that began with the U.S.-led invasion of Afghanistan in 2001, and which he acknowledged had required an   extraordinary sacrifice of blood and treasure .  We will ask our NATO allies and global partners to support our new strategy, with additional troops and funding increases in line with our own. We are confident they will,  Trump said. That comment signaled he would further increase pressure on U.S. partners who have already been jolted by his repeated demands to step up their contributions to NATO and his description of the alliance as  obsolete  - even though, since taking office, he has said this is no longer the case. NATO Secretary General Jens Stoltenberg said in a statement:  NATO remains fully committed to Afghanistan and I am looking forward to discussing the way ahead with (Defense) Secretary (James) Mattis and our Allies and international partners.  NATO has 12,000 troops in Afghanistan, and 15 countries have pledged more, Stoltenberg said. Britain, a leading NATO member, called the U.S. commitment  very welcome .  In my call with Secretary Mattis yesterday we agreed that despite the challenges, we have to stay the course in Afghanistan to help build up its fragile democracy and reduce the terrorist threat to the West,  Defence Secretary Michael Fallon said. Germany, which has borne the brunt of Trump s criticism over  the scale of its defense spending, also welcomed the new U.S. plan.  Our continued commitment is necessary on the path to stabilizing the country,  a government spokeswoman said. In June, European allies had already pledged more troops but had not given details on numbers, waiting for the Trump administration to outline its strategy for the region.Nearly 16 years after the U.S.-led invasion - a response to the Sept. 11 attacks which were planned by al Qaeda leader Osama bin Laden from Afghanistan - the country is still struggling with weak central government and a Taliban insurgency. Trump said he shared the frustration of the American people who were  weary of war without victory , but a hasty withdrawal would create a vacuum for groups like Islamic State and al Qaeda to fill. \n",
      "\n",
      "    Original Text Token Count: 559\n",
      "\n",
      "    Max Allowed Total Tokens (Title + Text): 512\n",
      "\n",
      "    Available Tokens for Text Summary: 496\n",
      "\n",
      "\n",
      "    Now rewrite the article text only (not the title) within the available token budget. Your output should be clean, self-contained, and informative. \n",
      "    Do not add any information that is not present in the original news text or do not censor the text.\n",
      "    Your output must be exactly text summary and nothing else. You are also not allowed to water-down or censor the text as the text may contain sensitive information related \n",
      "    to politics, race or religion. Your job is to just summarize the text and not censor/water-down the text in any way shape or form.\n",
      "    The summary should be concise, informative, and maintain the original meaning.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(total_prompts[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a8b5afd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 19248/19248 [00:47<00:00, 402.41it/s]\n",
      "Processed prompts: 100%|██████████| 19248/19248 [1:24:07<00:00,  3.81it/s, est. speed input: 4486.74 toks/s, output: 822.35 toks/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 18s, sys: 6.48 s, total: 1min 25s\n",
      "Wall time: 1h 24min 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "outputs = llm.generate(total_prompts, sampling_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ec68629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [output.outputs[0].text for output in outputs]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2917eb51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NATO allies welcomed President Donald Trump's decision to commit more forces to Afghanistan as part of a new US strategy. The US will send about 4,000 more troops to add to the 8,400 already deployed. Trump's speech did not define benchmarks for ending the war, but he asked allies to support the new strategy with additional troops and funding. NATO Secretary General Jens Stoltenberg said the alliance remains committed to Afghanistan and will discuss the way ahead with Defense Secretary James Mattis and allies. Britain, Germany, and other European allies welcomed the new US plan, citing the need to stabilize the country and reduce the terrorist threat. The US-led invasion of Afghanistan began in 2001, and the country remains weak with a Taliban insurgency nearly 16 years later. Trump said a hasty withdrawal would create a vacuum for groups like Islamic State and al Qaeda to fill.\n"
     ]
    }
   ],
   "source": [
    "print(results[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e383503e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame({\"Prompts\": total_prompts, \"Results\": results})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f461976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompts</th>\n",
       "      <th>Results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>Donald Trump wished Americans a Happy New Year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>Former Milwaukee Sheriff David Clarke is facin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>Donald Trump announced he'd return to work the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>Many people have raised alarm about Donald Tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>Abigail Disney, an heiress to the Disney empir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19243</th>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>North Korea and the US clashed at a U.N. forum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19244</th>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>North Korea and the United States clashed at a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19245</th>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>North Korea and the US clashed at the United N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19246</th>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>Two North Korean shipments to a Syrian governm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19247</th>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>NATO allies welcomed President Donald Trump's ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19248 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Prompts  \\\n",
       "0      <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "1      <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "2      <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "3      <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "4      <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "...                                                  ...   \n",
       "19243  <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "19244  <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "19245  <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "19246  <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "19247  <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "\n",
       "                                                 Results  \n",
       "0      Donald Trump wished Americans a Happy New Year...  \n",
       "1      Former Milwaukee Sheriff David Clarke is facin...  \n",
       "2      Donald Trump announced he'd return to work the...  \n",
       "3      Many people have raised alarm about Donald Tru...  \n",
       "4      Abigail Disney, an heiress to the Disney empir...  \n",
       "...                                                  ...  \n",
       "19243  North Korea and the US clashed at a U.N. forum...  \n",
       "19244  North Korea and the United States clashed at a...  \n",
       "19245  North Korea and the US clashed at the United N...  \n",
       "19246  Two North Korean shipments to a Syrian governm...  \n",
       "19247  NATO allies welcomed President Donald Trump's ...  \n",
       "\n",
       "[19248 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ac75961e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"llama3_2_3b_summary_results_FinalTesting.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5edb94a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# batch_size = 100\n",
    "# output_file = \"summarized_output.csv\"\n",
    "\n",
    "# # Write headers once\n",
    "# with open(output_file, \"w\", newline='', encoding='utf-8') as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     writer.writerow([\"original_text\", \"summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37eccaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in tqdm(range(0, len(total_prompts), batch_size)):\n",
    "#     batch_prompts = total_prompts[i:i + batch_size]\n",
    "\n",
    "#     outputs = llm.generate(batch_prompts, sampling_params)\n",
    "\n",
    "#     summaries = [out.outputs[0].text if out.outputs else \"\" for out in outputs]\n",
    "\n",
    "#     with open(output_file, \"a\", newline='', encoding='utf-8') as f:\n",
    "#         writer = csv.writer(f)\n",
    "#         for original, summary in zip(batch_prompts, summaries):\n",
    "#             writer.writerow([original, summary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e83059",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
