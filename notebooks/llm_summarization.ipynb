{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c336bf52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\neupa\\anaconda3\\envs\\capstone\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb123b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm import LLM, SamplingParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebad8dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HF_TOKEN\"] = \"HF_TOKEN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4695dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jun 22 18:33:42 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.133.20             Driver Version: 570.133.20     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A10G                    On  |   00000000:00:1E.0 Off |                    0 |\n",
      "|  0%   25C    P8              9W /  300W |       0MiB /  23028MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f39a366",
   "metadata": {},
   "source": [
    "# Loading our LLM onto vLLM and preparing tokenizer\n",
    "\n",
    "Selected LLM: [meta-llama/Llama-3.2-3B-Instruct](https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "709e2d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available!\n",
      "Using device: NVIDIA A10G\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available!\")\n",
    "    print(f\"Using device: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"No GPU. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8610daed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/Llama-3.2-3B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8681bfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_params = SamplingParams(temperature=0.1, top_p=1, max_tokens=512)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3586723d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-22 18:33:54 [config.py:823] This model supports multiple tasks: {'generate', 'reward', 'score', 'embed', 'classify'}. Defaulting to 'generate'.\n",
      "INFO 06-22 18:33:54 [config.py:2195] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "WARNING 06-22 18:33:56 [utils.py:2597] We must use the `spawn` multiprocessing start method. Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. See https://docs.vllm.ai/en/latest/usage/troubleshooting.html#python-multiprocessing for more information. Reason: CUDA is initialized\n",
      "WARNING 06-22 18:33:57 [env_override.py:17] NCCL_CUMEM_ENABLE is set to 0, skipping override. This may increase memory overhead with cudagraph+allreduce: https://github.com/NVIDIA/nccl/issues/1234\n",
      "INFO 06-22 18:34:00 [__init__.py:244] Automatically detected platform cuda.\n",
      "INFO 06-22 18:34:03 [core.py:455] Waiting for init message from front-end.\n",
      "INFO 06-22 18:34:03 [core.py:70] Initializing a V1 LLM engine (v0.9.1) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=25000, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[\"none\"],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\"],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"max_capture_size\":512,\"local_cache_dir\":null}\n",
      "WARNING 06-22 18:34:04 [utils.py:2737] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7a1b607cc110>\n",
      "INFO 06-22 18:34:04 [parallel_state.py:1065] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "WARNING 06-22 18:34:04 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "INFO 06-22 18:34:05 [gpu_model_runner.py:1595] Starting to load model meta-llama/Llama-3.2-3B-Instruct...\n",
      "INFO 06-22 18:34:05 [gpu_model_runner.py:1600] Loading model from scratch...\n",
      "INFO 06-22 18:34:05 [cuda.py:252] Using Flash Attention backend on V1 engine.\n",
      "INFO 06-22 18:34:05 [weight_utils.py:292] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:36<00:36, 36.85s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:47<00:00, 21.71s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:47<00:00, 23.98s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-22 18:34:54 [default_loader.py:272] Loading weights took 48.03 seconds\n",
      "INFO 06-22 18:34:54 [gpu_model_runner.py:1624] Model loading took 6.0165 GiB and 48.859937 seconds\n",
      "INFO 06-22 18:35:02 [backends.py:462] Using cache directory: /home/ubuntu/.cache/vllm/torch_compile_cache/e9dfdcf700/rank_0_0 for vLLM's torch.compile\n",
      "INFO 06-22 18:35:02 [backends.py:472] Dynamo bytecode transform time: 8.19 s\n",
      "INFO 06-22 18:35:06 [backends.py:161] Cache the graph of shape None for later use\n",
      "INFO 06-22 18:35:29 [backends.py:173] Compiling a graph for general shape takes 26.13 s\n",
      "INFO 06-22 18:35:37 [monitor.py:34] torch.compile takes 34.32 s in total\n",
      "INFO 06-22 18:35:38 [gpu_worker.py:227] Available KV cache memory: 12.61 GiB\n",
      "INFO 06-22 18:35:39 [kv_cache_utils.py:715] GPU KV cache size: 118,080 tokens\n",
      "INFO 06-22 18:35:39 [kv_cache_utils.py:719] Maximum concurrency for 25,000 tokens per request: 4.72x\n",
      "INFO 06-22 18:36:01 [gpu_model_runner.py:2048] Graph capturing finished in 23 secs, took 0.45 GiB\n",
      "INFO 06-22 18:36:01 [core.py:171] init engine (profile, create kv cache, warmup model) took 67.12 seconds\n"
     ]
    }
   ],
   "source": [
    "llm = LLM(model=model_id, dtype=torch.bfloat16, max_model_len=25000) # one of the prompts has lots of tokens so"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd889f8f",
   "metadata": {},
   "source": [
    "# Testing on a single prompt for speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a25e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = '''You are an expert summarizer helping a user prepare input for a sentence embedding model with a strict 512-token input limit.\n",
    "The user will always include the full **title** of the news article. Your job is to **rewrite or summarize the news article text only**, using no more than the available tokens provided. The goal is to preserve **all important meaning** from the article without exceeding the token budget.\n",
    "\n",
    "You must:\n",
    "- Leave the title unchanged\n",
    "- Output **only the rewritten article text**\n",
    "- Not include anything non-relevant stuff in your response\n",
    "\n",
    "You will be provided Input details.\n",
    "'''\n",
    "\n",
    "prompt = '''Input details:\n",
    "\n",
    "    Title: LAW ENFORCEMENT ON HIGH ALERT Following Threats Against Cops And Whites On 9-11By #BlackLivesMatter And #FYF911 Terrorists [VIDEO]\n",
    "\n",
    "    Title Token Count: 35\n",
    "\n",
    "    Original Text: No comment is expected from Barack Obama Members of the #FYF911 or #FukYoFlag and #BlackLivesMatter movements called for the lynching and hanging of white people and cops. They encouraged others on a radio show Tuesday night to  turn the tide  and kill white people and cops to send a message about the killing of black people in America.One of the F***YoFlag organizers is called  Sunshine.  She has a radio blog show hosted from Texas called,  Sunshine s F***ing Opinion Radio Show. A snapshot of her #FYF911 @LOLatWhiteFear Twitter page at 9:53 p.m. shows that she was urging supporters to  Call now!! #fyf911 tonight we continue to dismantle the illusion of white Below is a SNAPSHOT Twitter Radio Call Invite   #FYF911The radio show aired at 10:00 p.m. eastern standard time.During the show, callers clearly call for  lynching  and  killing  of white people.A 2:39 minute clip from the radio show can be heard here. It was provided to Breitbart Texas by someone who would like to be referred to as  Hannibal.  He has already received death threats as a result of interrupting #FYF911 conference calls.An unidentified black man said  when those mother f**kers are by themselves, that s when when we should start f***ing them up. Like they do us, when a bunch of them ni**ers takin  one of us out, that s how we should roll up.  He said,  Cause we already roll up in gangs anyway. There should be six or seven black mother f**ckers, see that white person, and then lynch their ass. Let s turn the tables. They conspired that if  cops started losing people,  then  there will be a state of emergency. He speculated that one of two things would happen,  a big-ass [R s?????] war,  or  ni**ers, they are going to start backin  up. We are already getting killed out here so what the f**k we got to lose? Sunshine could be heard saying,  Yep, that s true. That s so f**king true. He said,  We need to turn the tables on them. Our kids are getting shot out here. Somebody needs to become a sacrifice on their side.He said,  Everybody ain t down for that s**t, or whatever, but like I say, everybody has a different position of war.  He continued,  Because they don t give a f**k anyway.  He said again,  We might as well utilized them for that s**t and turn the tables on these n**ers. He said, that way  we can start lookin  like we ain t havin  that many casualties, and there can be more causalities on their side instead of ours. They are out their killing black people, black lives don t matter, that s what those mother f**kers   so we got to make it matter to them. Find a mother f**ker that is alone. Snap his ass, and then f***in hang him from a damn tree. Take a picture of it and then send it to the mother f**kers. We  just need one example,  and  then people will start watchin .  This will turn the tables on s**t, he said. He said this will start  a trickle-down effect.  He said that when one white person is hung and then they are just  flat-hanging,  that will start the  trickle-down effect.  He continued,  Black people are good at starting trends. He said that was how  to get the upper-hand. Another black man spoke up saying they needed to kill  cops that are killing us. The first black male said,  That will be the best method right there. Breitbart Texas previously reported how Sunshine was upset when  racist white people  infiltrated and disrupted one of her conference calls. She subsequently released the phone number of one of the infiltrators. The veteran immediately started receiving threatening calls.One of the #F***YoFlag movement supporters allegedly told a veteran who infiltrated their publicly posted conference call,  We are going to rape and gut your pregnant wife, and your f***ing piece of sh*t unborn creature will be hung from a tree. Breitbart Texas previously encountered Sunshine at a Sandra Bland protest at the Waller County Jail in Texas, where she said all white people should be killed. She told journalists and photographers,  You see this nappy-ass hair on my head?   That means I am one of those more militant Negroes.  She said she was at the protest because  these redneck mother-f**kers murdered Sandra Bland because she had nappy hair like me. #FYF911 black radicals say they will be holding the  imperial powers  that are actually responsible for the terrorist attacks on September 11th accountable on that day, as reported by Breitbart Texas. There are several websites and Twitter handles for the movement. Palmetto Star  describes himself as one of the head organizers. He said in a YouTube video that supporters will be burning their symbols of  the illusion of their superiority,  their  false white supremacy,  like the American flag, the British flag, police uniforms, and Ku Klux Klan hoods.Sierra McGrone or  Nocturnus Libertus  posted,  you too can help a young Afrikan clean their a** with the rag of oppression.  She posted two photos, one that appears to be herself, and a photo of a black man, wiping their naked butts with the American flag.For entire story: Breitbart News\n",
    "\n",
    "    Original Text Token Count: 1200\n",
    "\n",
    "    Max Allowed Total Tokens (Title + Text): 512\n",
    "\n",
    "    Available Tokens for Text Summary: 477\n",
    "\n",
    "\n",
    "    Now rewrite the article text only (not the title) within the available token budget. Your output should be clean, self-contained, and informative.\n",
    "    Do not add any information that is not present in the original news text. Your output must be exactly text summary and nothing else'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7d23b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79a2f044",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3094219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 100/100 [00:00<00:00, 341.67it/s]\n",
      "Processed prompts: 100%|██████████| 100/100 [00:08<00:00, 11.31it/s, est. speed input: 16734.03 toks/s, output: 2348.41 toks/s]\n"
     ]
    }
   ],
   "source": [
    "outputs = llm.generate([prompt]*100, sampling_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "174b6fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Members of the #FYF911 and #BlackLivesMatter movements called for the lynching and hanging of white people and cops, urging others to send a message about the killing of black people in America. A radio show host, Sunshine, encouraged supporters to kill white people and cops, saying \"Find a mother f**ker that is alone. Snap his ass, and then f***in hang him from a damn tree.\" \n",
      "\n",
      "A caller on the show said, \"When those mother f**kers are by themselves, that's when we should start f***ing them up.\" Another caller suggested lynching cops that are killing black people. Sunshine previously released the phone number of a veteran who infiltrated one of her conference calls, and he received threatening calls. \n",
      "\n",
      "Sunshine has made previous statements, including saying all white people should be killed and that she was at a Sandra Bland protest because \"these redneck mother-f**kers murdered Sandra Bland because she had nappy hair like me.\" The movement plans to hold the imperial powers accountable for the 9/11 terrorist attacks.\n"
     ]
    }
   ],
   "source": [
    "print(outputs[-1].outputs[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "232fe2db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.encode(outputs[-1].outputs[0].text, return_tensors='pt')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71676105",
   "metadata": {},
   "source": [
    "Well, processing 100 prompts took ~11 seconds, and we have an average of 2500 output tokens per second which is not bad at all. Lets process all prompts now. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5803d8d2",
   "metadata": {},
   "source": [
    "# Reading file and preparing prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fc8be57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Summary_prompts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22d26ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36879, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Input details:\\n\\n    Title: LAW ENFORCEMENT O...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Input details:\\n\\n    Title: Bobby Jindal, rai...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Input details:\\n\\n    Title: Latest Pipeline L...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Input details:\\n\\n    Title:  GOP Senator Just...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Input details:\\n\\n    Title: Schumer calls on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Input details:\\n\\n    Title: LAW ENFORCEMENT O...      1\n",
       "1  Input details:\\n\\n    Title: Bobby Jindal, rai...      0\n",
       "2  Input details:\\n\\n    Title: Latest Pipeline L...      1\n",
       "3  Input details:\\n\\n    Title:  GOP Senator Just...      1\n",
       "4  Input details:\\n\\n    Title: Schumer calls on ...      0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "385a3499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input details:\n",
      "\n",
      "    Title: LAW ENFORCEMENT ON HIGH ALERT Following Threats Against Cops And Whites On 9-11By #BlackLivesMatter And #FYF911 Terrorists [VIDEO]\n",
      "\n",
      "    Title Token Count: 35\n",
      "\n",
      "    Original Text: No comment is expected from Barack Obama Members of the #FYF911 or #FukYoFlag and #BlackLivesMatter movements called for the lynching and hanging of white people and cops. They encouraged others on a radio show Tuesday night to  turn the tide  and kill white people and cops to send a message about the killing of black people in America.One of the F***YoFlag organizers is called  Sunshine.  She has a radio blog show hosted from Texas called,  Sunshine s F***ing Opinion Radio Show. A snapshot of her #FYF911 @LOLatWhiteFear Twitter page at 9:53 p.m. shows that she was urging supporters to  Call now!! #fyf911 tonight we continue to dismantle the illusion of white Below is a SNAPSHOT Twitter Radio Call Invite   #FYF911The radio show aired at 10:00 p.m. eastern standard time.During the show, callers clearly call for  lynching  and  killing  of white people.A 2:39 minute clip from the radio show can be heard here. It was provided to Breitbart Texas by someone who would like to be referred to as  Hannibal.  He has already received death threats as a result of interrupting #FYF911 conference calls.An unidentified black man said  when those mother f**kers are by themselves, that s when when we should start f***ing them up. Like they do us, when a bunch of them ni**ers takin  one of us out, that s how we should roll up.  He said,  Cause we already roll up in gangs anyway. There should be six or seven black mother f**ckers, see that white person, and then lynch their ass. Let s turn the tables. They conspired that if  cops started losing people,  then  there will be a state of emergency. He speculated that one of two things would happen,  a big-ass [R s?????] war,  or  ni**ers, they are going to start backin  up. We are already getting killed out here so what the f**k we got to lose? Sunshine could be heard saying,  Yep, that s true. That s so f**king true. He said,  We need to turn the tables on them. Our kids are getting shot out here. Somebody needs to become a sacrifice on their side.He said,  Everybody ain t down for that s**t, or whatever, but like I say, everybody has a different position of war.  He continued,  Because they don t give a f**k anyway.  He said again,  We might as well utilized them for that s**t and turn the tables on these n**ers. He said, that way  we can start lookin  like we ain t havin  that many casualties, and there can be more causalities on their side instead of ours. They are out their killing black people, black lives don t matter, that s what those mother f**kers   so we got to make it matter to them. Find a mother f**ker that is alone. Snap his ass, and then f***in hang him from a damn tree. Take a picture of it and then send it to the mother f**kers. We  just need one example,  and  then people will start watchin .  This will turn the tables on s**t, he said. He said this will start  a trickle-down effect.  He said that when one white person is hung and then they are just  flat-hanging,  that will start the  trickle-down effect.  He continued,  Black people are good at starting trends. He said that was how  to get the upper-hand. Another black man spoke up saying they needed to kill  cops that are killing us. The first black male said,  That will be the best method right there. Breitbart Texas previously reported how Sunshine was upset when  racist white people  infiltrated and disrupted one of her conference calls. She subsequently released the phone number of one of the infiltrators. The veteran immediately started receiving threatening calls.One of the #F***YoFlag movement supporters allegedly told a veteran who infiltrated their publicly posted conference call,  We are going to rape and gut your pregnant wife, and your f***ing piece of sh*t unborn creature will be hung from a tree. Breitbart Texas previously encountered Sunshine at a Sandra Bland protest at the Waller County Jail in Texas, where she said all white people should be killed. She told journalists and photographers,  You see this nappy-ass hair on my head?   That means I am one of those more militant Negroes.  She said she was at the protest because  these redneck mother-f**kers murdered Sandra Bland because she had nappy hair like me. #FYF911 black radicals say they will be holding the  imperial powers  that are actually responsible for the terrorist attacks on September 11th accountable on that day, as reported by Breitbart Texas. There are several websites and Twitter handles for the movement. Palmetto Star  describes himself as one of the head organizers. He said in a YouTube video that supporters will be burning their symbols of  the illusion of their superiority,  their  false white supremacy,  like the American flag, the British flag, police uniforms, and Ku Klux Klan hoods.Sierra McGrone or  Nocturnus Libertus  posted,  you too can help a young Afrikan clean their a** with the rag of oppression.  She posted two photos, one that appears to be herself, and a photo of a black man, wiping their naked butts with the American flag.For entire story: Breitbart News\n",
      "\n",
      "    Original Text Token Count: 1200\n",
      "\n",
      "    Max Allowed Total Tokens (Title + Text): 512\n",
      "\n",
      "    Available Tokens for Text Summary: 477\n",
      "\n",
      "\n",
      "    Now rewrite the article text only (not the title) within the available token budget. Your output should be clean, self-contained, and informative. \n",
      "    Do not add any information that is not present in the original news text or do not censor the text.\n",
      "    Your output must be exactly text summary and nothing else. You are also not allowed to water-down or censor the text as the text may contain sensitive information related \n",
      "    to politics, race or religion. Your job is to just summarize the text and not censor/water-down the text in any way shape or form.\n",
      "    The summary should be concise, informative, and maintain the original meaning.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(df.text.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20eb91c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a0bc45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36879/36879 [03:18<00:00, 185.53it/s]\n"
     ]
    }
   ],
   "source": [
    "total_prompts = []\n",
    "token_count = []\n",
    "\n",
    "for current_prompt in tqdm(df.text.values):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": current_prompt},\n",
    "    ]\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    total_prompts.append(prompt)\n",
    "    encoded = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    token_count.append(len(encoded[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a338a01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['token_count'] = token_count\n",
    "df['prompt'] = total_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c22556b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(count    36879.000000\n",
       " mean      1436.214838\n",
       " std        958.622055\n",
       " min        555.000000\n",
       " 25%        969.000000\n",
       " 50%       1183.000000\n",
       " 75%       1589.000000\n",
       " max      42427.000000\n",
       " Name: token_count, dtype: float64,\n",
       " np.float64(10766.0))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"token_count\"].describe(), df[\"token_count\"].quantile(0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d0a9d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"token_count\"] < 20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d905f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_prompts = df.prompt.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06873499",
   "metadata": {},
   "source": [
    "# Summarization using vLLM + Llama-3.2-3B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "475e5cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 22 Jun 2025\n",
      "\n",
      "You are an expert summarizer helping a user prepare input for a sentence embedding model with a strict 512-token input limit.\n",
      "The user will always include the full **title** of the news article. Your job is to **rewrite or summarize the news article text only**, using no more than the available tokens provided. The goal is to preserve **all important meaning** from the article without exceeding the token budget.\n",
      "\n",
      "You must:\n",
      "- Leave the title unchanged\n",
      "- Output **only the rewritten article text**\n",
      "- Not include anything non-relevant stuff in your response\n",
      "\n",
      "You will be provided Input details.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Input details:\n",
      "\n",
      "    Title:  Florida Judge Blames Rape Victim For Attending Music Festival\n",
      "\n",
      "    Title Token Count: 12\n",
      "\n",
      "    Original Text: The Ultra Music Festival in Miami is one of the largest electronic dance music festivals in the World. Over 170,000 people attended this year, and with it came several arrests, but one of the most horrific was the rape of a tourist from Brazil, which was blamed by a Florida judge due to the festival.Transit worker for the Department of Transportation and Public Works in Miami, Carl Lee Wilt, allegedly took the 22-year-old girl into a utility closet after she was prevented from boarding a public transit train for being too intoxicated, according to the police report.A witness harassed police officers in the area for 15 minutes until they decided to knock on the utility door, which Wilt opened five minutes later with his pants undone. Police said Wilt admitted to sexually assaulting the girl, but apparently stopped when she defecated herself.The girl told officers she had no recollection of how she met Wilt or what happened during their encounter.Miami-Dade judge Nushin Sayfie ordered Wilt be held without bond, who faces kidnapping and sexual battery charges, but then proceeded to blame the victim and the Ultra Music Festival for the rape. This is why we shouldn t let our kids go to Ultra   right here,  Sayfie said, who was appointed by former Republican Florida Governor Charlie Crist in 2007. Her argument is straight out of the 1984 Kevin Bacon film, Footloose, in which a small town has banned dancing and rock music. Unlike policing victims  behavior, educating people about rape can make lasting progress toward prevention. One study showed that after just one hour of education on sexual assault, men were less likely to believe myths about rape or consider being sexually coercive,  wrote Suzannah Weiss in a 2015 article for Bustle.  Once we recognize that sexual assault can happen to anyone, we can stop wondering what the victim did to deserve it and start wondering what allowed the perpetrator to go through with it. That s the only way we can gain the control we crave and create the  just world  we want to believe in. It is deeply disturbing this type of  blame-the-victim  language is coming from a judge in one of the biggest cities in the country. Carl Lee Wilt would have raped someone given the opportunity to, no matter whether there was a dance festival going on or not. Judge Sayfie should reevaluate her own judgment on these issues before presiding over another similar case. Featured image via Flickr\n",
      "\n",
      "    Original Text Token Count: 501\n",
      "\n",
      "    Max Allowed Total Tokens (Title + Text): 512\n",
      "\n",
      "    Available Tokens for Text Summary: 500\n",
      "\n",
      "\n",
      "    Now rewrite the article text only (not the title) within the available token budget. Your output should be clean, self-contained, and informative. \n",
      "    Do not add any information that is not present in the original news text or do not censor the text.\n",
      "    Your output must be exactly text summary and nothing else. You are also not allowed to water-down or censor the text as the text may contain sensitive information related \n",
      "    to politics, race or religion. Your job is to just summarize the text and not censor/water-down the text in any way shape or form.\n",
      "    The summary should be concise, informative, and maintain the original meaning.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(total_prompts[-10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c9a7d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 22 Jun 2025\n",
      "\n",
      "You are an expert summarizer helping a user prepare input for a sentence embedding model with a strict 512-token input limit.\n",
      "The user will always include the full **title** of the news article. Your job is to **rewrite or summarize the news article text only**, using no more than the available tokens provided. The goal is to preserve **all important meaning** from the article without exceeding the token budget.\n",
      "\n",
      "You must:\n",
      "- Leave the title unchanged\n",
      "- Output **only the rewritten article text**\n",
      "- Not include anything non-relevant stuff in your response\n",
      "\n",
      "You will be provided Input details.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Input details:\n",
      "\n",
      "    Title: Goldman Sachs Endorses Hillary Clinton For President\n",
      "\n",
      "    Title Token Count: 11\n",
      "\n",
      "    Original Text: Goldman Sachs Endorses Hillary Clinton For President For Goldman Sachs, was there really any other choice this cycle? | October 27, 2016 Be Sociable, Share! Lloyd Blankfein, CEO of Goldman Sachs, is greeted by Hillary Clinton at a panel discussion at the Clinton Global Initiative, Sept. 24, 2014 in New York. \n",
      "Published in partnership with Shadowproof . \n",
      "He’s with her. On Sunday, former Secretary of State Hillary Clinton earned the endorsement of Goldman Sachs CEO Lloyd Blankfein —an endorsement she had been working toward for years. \n",
      "As was revealed by Wikileaks, Hillary Clinton spent the run up to her presidential campaign giving speeches to Goldman Sachs and other Wall Street banks, where she praised their talents and explained her positions on financial regulation. \n",
      "On October 24, 2013, Clinton told Goldman Sachs that Dodd-Frank had to be done mostly for “political reasons” because Congress needed to look like it was doing something about the crisis. She said, “There’s nothing magic about regulations, too much is bad, too little is bad. How do you get to the golden key, how do we figure out what works? And the people that know the industry better than anybody are the people who work in the industry.” \n",
      "Yes, she essentially endorsed Wall Street writing the rules because Wall Street knows its business best and complained to Goldman Sachs that regulations had frightened bankers. \n",
      "“I mean, right now, there are so many places in our country where the banks are not doing what they need to do because they’re scared of regulations, they’re scared of the other shoe dropping, they’re just plain scared, so credit is not flowing the way it needs to to restart economic growth,” Clinton said. “So people are, you know, a little — they’re still uncertain, and they’re uncertain both because they don’t know what might come next in terms of regulations, but they’re also uncertain because of changes in a global economy that we’re only beginning to take hold of.” \n",
      "Music to Wall Street’s ears. For Goldman Sachs, was there really any other choice this cycle? After all, they did pay Hillary Clinton $675,000 for those three speeches, and have generously supported her political career. \n",
      "Despite her private comments to Goldman Sachs, Hillary Clinton has taken a tough public position on Wall Street during the campaign, likely due to Senator Bernie Sanders’ success in the primaries. Of course, Wikileaks also revealed that Clinton told the National Multi-housing Council in a private speech that “you need both a public and a private position.” \n",
      "So the real question is, what do Blankfein and Goldman want in return and what is Clinton’s private position on giving it to them? Be Sociable, Share!\n",
      "\n",
      "    Original Text Token Count: 568\n",
      "\n",
      "    Max Allowed Total Tokens (Title + Text): 512\n",
      "\n",
      "    Available Tokens for Text Summary: 501\n",
      "\n",
      "\n",
      "    Now rewrite the article text only (not the title) within the available token budget. Your output should be clean, self-contained, and informative. \n",
      "    Do not add any information that is not present in the original news text or do not censor the text.\n",
      "    Your output must be exactly text summary and nothing else. You are also not allowed to water-down or censor the text as the text may contain sensitive information related \n",
      "    to politics, race or religion. Your job is to just summarize the text and not censor/water-down the text in any way shape or form.\n",
      "    The summary should be concise, informative, and maintain the original meaning.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(total_prompts[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8b5afd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 36868/36868 [02:13<00:00, 277.17it/s]\n",
      "Processed prompts: 100%|██████████| 36868/36868 [3:29:01<00:00,  2.94it/s, est. speed input: 4200.93 toks/s, output: 694.15 toks/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 35s, sys: 14.8 s, total: 3min 50s\n",
      "Wall time: 3h 31min 14s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "outputs = llm.generate(total_prompts, sampling_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec68629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [output.outputs[0].text for output in outputs]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2917eb51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goldman Sachs CEO Lloyd Blankfein endorsed Hillary Clinton for president, a move she had been working towards for years. The endorsement comes after Clinton gave speeches to Goldman Sachs and other Wall Street banks, praising their talents and explaining her positions on financial regulation. In 2013, Clinton told Goldman Sachs that Dodd-Frank had to be passed for \"political reasons\" and that regulations should be written by those who know the industry best. She also stated that banks are scared of regulations and that this is hindering economic growth. Clinton has taken a tough public position on Wall Street during the campaign, but her private comments to Goldman Sachs suggest she may be open to giving them influence.\n"
     ]
    }
   ],
   "source": [
    "print(results[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e383503e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame({\"Prompts\": total_prompts, \"Results\": results})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f461976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompts</th>\n",
       "      <th>Results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>Members of the #FYF911 and #BlackLivesMatter m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>Louisiana Gov. Bobby Jindal, a Hindu by birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>Underscoring the dangers of America’s unreliab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>Sen. Ben Sasse (R-Neb.) took aim at Alt-Right ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>Charles Schumer, the top Democrat in the U.S. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36863</th>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>Hackers believed to be working for the Russian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36864</th>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>Giuliani demands that Democrats apologize for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36865</th>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>Thousands of migrants flooded into a train sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36866</th>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>Donald Trump's combative style has buffeted Me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36867</th>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>Goldman Sachs CEO Lloyd Blankfein endorsed Hil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36868 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Prompts  \\\n",
       "0      <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "1      <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "2      <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "3      <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "4      <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "...                                                  ...   \n",
       "36863  <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "36864  <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "36865  <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "36866  <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "36867  <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "\n",
       "                                                 Results  \n",
       "0      Members of the #FYF911 and #BlackLivesMatter m...  \n",
       "1      Louisiana Gov. Bobby Jindal, a Hindu by birth,...  \n",
       "2      Underscoring the dangers of America’s unreliab...  \n",
       "3      Sen. Ben Sasse (R-Neb.) took aim at Alt-Right ...  \n",
       "4      Charles Schumer, the top Democrat in the U.S. ...  \n",
       "...                                                  ...  \n",
       "36863  Hackers believed to be working for the Russian...  \n",
       "36864  Giuliani demands that Democrats apologize for ...  \n",
       "36865  Thousands of migrants flooded into a train sta...  \n",
       "36866  Donald Trump's combative style has buffeted Me...  \n",
       "36867  Goldman Sachs CEO Lloyd Blankfein endorsed Hil...  \n",
       "\n",
       "[36868 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac75961e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"llama3_2_3b_summary_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5edb94a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# batch_size = 100\n",
    "# output_file = \"summarized_output.csv\"\n",
    "\n",
    "# # Write headers once\n",
    "# with open(output_file, \"w\", newline='', encoding='utf-8') as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     writer.writerow([\"original_text\", \"summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37eccaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in tqdm(range(0, len(total_prompts), batch_size)):\n",
    "#     batch_prompts = total_prompts[i:i + batch_size]\n",
    "\n",
    "#     outputs = llm.generate(batch_prompts, sampling_params)\n",
    "\n",
    "#     summaries = [out.outputs[0].text if out.outputs else \"\" for out in outputs]\n",
    "\n",
    "#     with open(output_file, \"a\", newline='', encoding='utf-8') as f:\n",
    "#         writer = csv.writer(f)\n",
    "#         for original, summary in zip(batch_prompts, summaries):\n",
    "#             writer.writerow([original, summary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e83059",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
